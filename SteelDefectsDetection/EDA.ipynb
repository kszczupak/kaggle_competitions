{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from fastai.datasets import Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# base_path = Config.data_path()\n",
    "base_path = Path('/mnt/e/MojePliki/Programy/kaggle_data')\n",
    "data_path = base_path/'Steel_Defects_Detection'\n",
    "competition_name = 'severstal-steel-defect-detection'\n",
    "data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                    size  creationDate         \r\n",
      "---------------------  -----  -------------------  \r\n",
      "train.csv               18MB  2019-07-18 01:25:58  \r\n",
      "sample_submission.csv  141KB  2019-07-18 01:26:00  \r\n",
      "train_images.zip         1GB  2019-07-18 01:26:19  \r\n",
      "test_images.zip        129MB  2019-07-18 01:26:20  \r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions files -c {competition_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading severstal-steel-defect-detection.zip to /mnt/e/MojePliki/Programy/kaggle_data/Steel_Defects_Detection\n",
      "100%|███████████████████████████████████████| 1.29G/1.29G [26:12<00:00, 907kB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download --force -c {competition_name} -p {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/krzysiek/.fastai/data/Steel_Defects_Detection/train.csv.zip'),\n",
       " PosixPath('/home/krzysiek/.fastai/data/Steel_Defects_Detection/test_images.zip'),\n",
       " PosixPath('/home/krzysiek/.fastai/data/Steel_Defects_Detection/sample_submission.csv'),\n",
       " PosixPath('/home/krzysiek/.fastai/data/Steel_Defects_Detection/train_images.zip')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unziping train.csv.zip ...\n",
      "Done\n",
      "Unziping train_images.zip ...\n",
      "Done\n",
      "Unziping test_images.zip ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "file_name = \"train.csv.zip\"\n",
    "print(f\"Unziping {file_name} ...\")\n",
    "with ZipFile(data_path/file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)\n",
    "\n",
    "os.remove(data_path/file_name)\n",
    "print(\"Done\")\n",
    "\n",
    "file_name = \"train_images.zip\"\n",
    "print(f\"Unziping {file_name} ...\")\n",
    "train_files_destination = data_path/'train_images'\n",
    "train_files_destination.mkdir()\n",
    "with ZipFile(data_path/file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(train_files_destination)\n",
    "\n",
    "os.remove(data_path/file_name)\n",
    "print(\"Done\")\n",
    "\n",
    "file_name = \"test_images.zip\"\n",
    "print(f\"Unziping {file_name} ...\")\n",
    "test_files_destination = data_path/'test_images'\n",
    "test_files_destination.mkdir()\n",
    "with ZipFile(data_path/file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(test_files_destination)\n",
    "\n",
    "os.remove(data_path/file_name)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/e/MojePliki/Programy/kaggle_data/Steel_Defects_Detection/sample_submission.csv'),\n",
       " PosixPath('/mnt/e/MojePliki/Programy/kaggle_data/Steel_Defects_Detection/test_images'),\n",
       " PosixPath('/mnt/e/MojePliki/Programy/kaggle_data/Steel_Defects_Detection/train.csv'),\n",
       " PosixPath('/mnt/e/MojePliki/Programy/kaggle_data/Steel_Defects_Detection/train_images')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train df\n",
    "\n",
    "train_df['Image_Id'] = train_df['ImageId_ClassId'].apply(lambda x: x[:-2])\n",
    "train_df['Class_Id'] = train_df['ImageId_ClassId'].apply(lambda x: x[-1:])\n",
    "train_df.drop('ImageId_ClassId', axis=1, inplace=True)\n",
    "train_df.set_index('Image_Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Class_Id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002cc93b.jpg</th>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002cc93b.jpg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002cc93b.jpg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002cc93b.jpg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00031f466.jpg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   EncodedPixels Class_Id\n",
       "Image_Id                                                                 \n",
       "0002cc93b.jpg  29102 12 29346 24 29602 24 29858 24 30114 24 3...        1\n",
       "0002cc93b.jpg                                                NaN        2\n",
       "0002cc93b.jpg                                                NaN        3\n",
       "0002cc93b.jpg                                                NaN        4\n",
       "00031f466.jpg                                                NaN        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = set(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(data_path/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId EncodedPixels\n",
       "0  004f40c73.jpg_1           1 1\n",
       "1  004f40c73.jpg_2           1 1\n",
       "2  004f40c73.jpg_3           1 1\n",
       "3  004f40c73.jpg_4           1 1\n",
       "4  006f39c41.jpg_1           1 1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = submission['ImageId_ClassId'].apply(lambda x: x[:-2])\n",
    "test_images = set(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((data_path/'test_images').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df[(train_df['Class_Id'] == '4') & (~train_df['EncodedPixels'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Class_Id'] == '3'].loc['0002cc93b.jpg']['EncodedPixels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12568/12568 [01:22<00:00, 152.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images without any defects: 5902/12568 (46%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "defects_count = defaultdict(int)\n",
    "num_of_defects_in_image = defaultdict(int)\n",
    "has_defects_labels = dict()\n",
    "\n",
    "# for train_image in tqdm_notebook(train_images):\n",
    "for train_image in tqdm(train_images):\n",
    "    defects_in_image = 0\n",
    "    image_df = train_df.loc[train_image]\n",
    "    \n",
    "    for defect_class in '1234':\n",
    "#         breakpoint()\n",
    "        if image_df[image_df['Class_Id'] == defect_class]['EncodedPixels'].notnull().any():\n",
    "            defects_count[defect_class] += 1\n",
    "            defects_in_image += 1\n",
    "    \n",
    "    num_of_defects_in_image[defects_in_image] += 1\n",
    "    has_defects_labels[train_image] = 1 if defects_in_image else 0\n",
    "    \n",
    "without_defect = num_of_defects_in_image[0]\n",
    "print(f\"Images without any defects: {without_defect}/{len(train_images)} ({100 * without_defect//len(train_images)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels dict to file\n",
    "with open(data_path/'defect_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(has_defects_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'3': 5150, '4': 801, '1': 897, '2': 247})\n",
      "defaultdict(<class 'int'>, {1: 6239, 0: 5902, 2: 425, 3: 2})\n"
     ]
    }
   ],
   "source": [
    "print(defects_count)\n",
    "print(num_of_defects_in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Class')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(defects_count.keys()), y=list(defects_count.values()), ax=ax)\n",
    "ax.set_title(\"# of images with given defect\")\n",
    "ax.set_xlabel('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of defects')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(num_of_defects_in_image.keys()), y=list(num_of_defects_in_image.values()), ax=ax)\n",
    "ax.set_title(\"# of defects per image\")\n",
    "ax.set_xlabel('# of defects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/krzysiek/.torch/models/resnet18-5c106cde.pth\n",
      "46827520it [00:01, 29778805.97it/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_sandbox]",
   "language": "python",
   "name": "conda-env-kaggle_sandbox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
